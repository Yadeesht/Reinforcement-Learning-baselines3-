{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a878ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb1ac52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import os\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1705f35c",
   "metadata": {},
   "source": [
    "## environmental setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15e5c899",
   "metadata": {},
   "outputs": [],
   "source": [
    "env=gym.make(\"CartPole-v1\",render_mode='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36ee6abc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yadee\\anaconda3\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 score: 21.0\n",
      "Episode: 2 score: 42.0\n",
      "Episode: 3 score: 42.0\n",
      "Episode: 4 score: 23.0\n",
      "Episode: 5 score: 11.0\n"
     ]
    }
   ],
   "source": [
    "episode=5\n",
    "for i in range(1,episode+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score=0\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action=env.action_space.sample()\n",
    "        n_state,reward,done,truncated,info = env.step(action)\n",
    "        score+=reward\n",
    "    print(\"Episode: {} score: {}\".format(i,score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83ea147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make your direcory\n",
    "log_path = os.path.join(\"training\", \"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12a8ec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(log_path, exist_ok=True) # i am creating the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f42aa32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yadee\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "env=gym.make(\"CartPole-v1\",render_mode=\"human\")\n",
    "env = DummyVecEnv([lambda:env])\n",
    "model = PPO(\"MlpPolicy\",env,verbose=1,tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91526d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to training\\logs\\PPO_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yadee\\anaconda3\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 45   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 45   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x13a28c7a910>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=20)# we can increase if we want the timesteps to improve the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42337bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10a2ad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_path=os.path.join(\"training\",\"saved models\",\"PPO_Model_cartpole\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73fbb312",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(PPO_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab51bb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ca887e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=PPO.load(PPO_path,env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9fedc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to training\\logs\\PPO_13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yadee\\anaconda3\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 45   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 44   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x18481f0e410>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93543bd8",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c8c1e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yadee\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(341.2, 138.3833805050303)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model,env,n_eval_episodes=10,render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e18552f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbc7b4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yadee\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n",
      "C:\\Users\\yadee\\anaconda3\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.6     |\n",
      "|    ep_rew_mean     | 21.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 1704     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 27.2        |\n",
      "|    ep_rew_mean          | 27.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 878         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008332024 |\n",
      "|    clip_fraction        | 0.089       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.687      |\n",
      "|    explained_variance   | -0.000795   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.4         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 50.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 35.6        |\n",
      "|    ep_rew_mean          | 35.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 816         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008409698 |\n",
      "|    clip_fraction        | 0.0582      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.669      |\n",
      "|    explained_variance   | 0.0846      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    value_loss           | 39.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 47.9        |\n",
      "|    ep_rew_mean          | 47.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 714         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008821458 |\n",
      "|    clip_fraction        | 0.0851      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.632      |\n",
      "|    explained_variance   | 0.207       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    value_loss           | 54.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 62.7        |\n",
      "|    ep_rew_mean          | 62.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 653         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008698456 |\n",
      "|    clip_fraction        | 0.0766      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.612      |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29.3        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    value_loss           | 60.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yadee\\anaconda3\\Lib\\site-packages\\gym\\envs\\classic_control\\cartpole.py:211: UserWarning: \u001b[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym(\"CartPole-v1\", render_mode=\"rgb_array\")\u001b[0m\n",
      "  gym.logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Score: 299.0\n",
      "Episode: 2, Score: 149.0\n",
      "Episode: 3, Score: 266.0\n",
      "Episode: 4, Score: 238.0\n",
      "Episode: 5, Score: 370.0\n"
     ]
    }
   ],
   "source": [
    "pygame.init()\n",
    "\n",
    "# Create the environment\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# Train the model\n",
    "model = PPO('MlpPolicy', env, verbose=1)\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "# Number of episodes to test\n",
    "episode = 5\n",
    "\n",
    "for i in range(1, episode + 1):\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done,t, info = env.step(action)\n",
    "        score += reward\n",
    "        env.render()\n",
    "\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                pygame.quit()\n",
    "\n",
    "    print(f'Episode: {i}, Score: {score}')\n",
    "\n",
    "env.close()\n",
    "pygame.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5e9fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efc35472",
   "metadata": {},
   "source": [
    "# viewing logs in tenserboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ca1a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_log_path=os.path.join(log_path,\"PPO_7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fefd52d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training\\\\logs\\\\PPO_7'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_log_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e63f8ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tensorboard --logdir=(training_log_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eefb39",
   "metadata": {},
   "source": [
    "# callback statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4f5073c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import EvalCallback,StopTrainingOnRewardThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7909e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path=os.path.join(\"training\",\"Saved Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d1bd876",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stop_callback = StopTrainingOnRewardThreshold(reward_threshold=200,verbose=1)\n",
    "eval_callback = EvalCallback(env,\n",
    "                             callback_on_new_best=stop_callback,\n",
    "                             eval_freq=10000,\n",
    "                             best_model_save_path=save_path,\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5daaae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "model = PPO(\"MlpPolicy\",env,verbose=1,tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02e6985e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to training\\logs\\PPO_14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yadee\\anaconda3\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 45   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 44   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x22488d83d90>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=1000,callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c908906",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b74fe1f",
   "metadata": {},
   "source": [
    "# change the policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "455c3bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_arch = [dict(pi=[128,128,128,128],vf=[128,128,128,128])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "981c7194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yadee\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:486: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = PPO(\"MlpPolicy\",env,verbose=1,tensorboard_log=log_path,policy_kwargs={\"net_arch\":net_arch})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f2a02f",
   "metadata": {},
   "source": [
    "# using alternaive algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "303fcbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce9582d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "model = DQN(\"MlpPolicy\",env,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fb170c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ecd890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ece2a52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bcde64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
